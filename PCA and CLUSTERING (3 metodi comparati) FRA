---
title: "R Notebook"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Data preparation
```{r}

options(scipen = 99999999)
library(cluster)
library(ComplexUpset)
library(readr)
library(readxl)
library(ggplot2)
library(dplyr)
library(FactoMineR)
library(factoextra)
library(tidyr)
library(dbscan)
library(reshape2)
# ~

# Caricamento del file Excel
data <- read_excel("[01]DB Esecuzione penale esterna.xlsx", na= '-')

# Sostituzione valori da stringa a numerici
data$"In carico all'inizio dell'anno da periodi precedenti" <- as.numeric(data$"In carico all'inizio dell'anno da periodi precedenti")
data$"Presi in carico nell'anno" <- as.numeric(data$"Presi in carico nell'anno")
data$"Totale soggetti in carico" <- as.numeric(data$"Totale soggetti in carico")
data$"Affidamento in prova al servizio sociale" <- as.numeric(data$"Affidamento in prova al servizio sociale")
data$"Detenzione domiciliare" <- as.numeric(data$"Detenzione domiciliare")
data$Semilibertà <- as.numeric(data$Semilibertà)
data$Semidetenzione <- as.numeric(data$Semidetenzione)
data$"Libertà controllata" <- as.numeric(data$"Libertà controllata")
data$"Detenzione domiciliare sostitutiva" <- as.numeric(data$"Detenzione domiciliare sostitutiva")
data$"Semilibertà sostitutiva" <- as.numeric(data$"Semilibertà sostitutiva")
data$"Lavoro di pubblica utilità sostitutivo" <- as.numeric(data$"Lavoro di pubblica utilità sostitutivo")
data$"Libertà vigilata" <- as.numeric(data$"Libertà vigilata")
data$"Lavoro di pubblica utilità - violazione legge sugli stupefacenti" <- as.numeric(data$"Lavoro di pubblica utilità - violazione legge sugli stupefacenti")
data$"Lavoro di pubblica utilità - violazione codice della strada" <- as.numeric(data$"Lavoro di pubblica utilità - violazione codice della strada")
data$"Sospensione condizionale della pena" <- as.numeric(data$"Sospensione condizionale della pena")
data$"Messa alla prova" <- as.numeric(data$"Messa alla prova")

# Merge colonne Lavoro di pubblica utilità
# Trova le colonne che contengono "Lavoro di pubblica utilità"
utilita_cols <- grep("Lavoro di pubblica utilità", colnames(data), value = TRUE)
# Visualizza le colonne trovate
print(utilita_cols)  
# Crea una nuova colonna come somma di tutte le colonne trovate
data$Lavoro_pubblica_utilita_totale <- rowSums(data[, utilita_cols], na.rm = TRUE)
# Verifica il risultato
head(data[, c(utilita_cols, "Lavoro_pubblica_utilita_totale")])

# Filtraggio colonne 
data <- data[c(1,2,3,4,5,6,7,8,15,19,20)]

# Selezione delle variabili numeriche
data_numeric <- data %>% select(-Region, -Municipality)

# Sostituzione dei NA con la media delle colonne
data_cleaned <- data_numeric %>%
  mutate(across(everything(), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))

```


PCA
```{r}

# Standardizzazione delle variabili numeriche
data_scaled <- scale(data_cleaned)

# Calcolo delle PCA
pca_result <- PCA(data_scaled, graph = FALSE)

# Grafico della varianza spiegata
fviz_eig(pca_result, addlabels = TRUE)
# Biplot per visualizzare le variabili
fviz_pca_var(pca_result, col.var = "black")
# Grafico del contributo delle variabili
fviz_cos2(pca_result, choice = "var", axes = 1:2)
# Biplot con variabili colorate in base al cos²
fviz_pca_var(pca_result, col.var = "cos2",
             gradient.cols = c("black", "orange", "green"),
             repel = TRUE)
#Proiezione delle osservazioni sulle prime due componenti principali
pca_data <- data.frame(pca_result$ind$coord)
ggplot(pca_data, aes(x = Dim.1, y = Dim.2)) +
  geom_point() +
  theme_minimal() +
  labs(title = "Proiezione sulle prime due componenti principali",
       x = "PCA 1", y = "PCA 2")

# Aggiunta colonne Region e Municipality
pca_data$Region <- data$Region
pca_data$Municipality <- data$Municipality

# Andiamo a mettere i colori alle occorrenze delle varie regioni (le varie strisce sono gli anni che vengono presi in considerazione)
ggplot(pca_data, aes(x = Dim.1, y = Dim.2, color = Region)) +
  geom_point(size = 3) +
  theme_minimal() +
  labs(title = "Proiezione con regioni colorate (palette personalizzata)",
       x = "PCA 1", y = "PCA 2") +
  scale_color_manual(values = c(
    "red", "blue", "green", "orange", "purple", "brown", "pink", "cyan", "yellow", "black",
    "darkred", "darkblue", "darkgreen", "gold", "violet", "chocolate", "turquoise", "gray", "darkorange", "navy"
  ))

# Ora vado ad identificare quali sono le variabili sotto a PCA 1/2/3
# Loadings delle variabili
loadings <- pca_result$var$coord
# Visualizza i loadings per le prime tre componenti
head(loadings[, 1:3])
# Ordina le variabili in base all'importanza per PCA 1
loading_pca1 <- loadings[order(abs(loadings[, 1]), decreasing = TRUE), 1]
# Ordina per PCA 2
loading_pca2 <- loadings[order(abs(loadings[, 2]), decreasing = TRUE), 2]
# Ordina per PCA 3
loading_pca3 <- loadings[order(abs(loadings[, 3]), decreasing = TRUE), 3]
# Visualizza i risultati
loading_pca1
loading_pca2
loading_pca3

# Visualizza il contributo delle variabili per PCA 1 e PCA 2
fviz_pca_var(pca_result, axes = c(1, 2),
             col.var = "contrib",
             gradient.cols = c("blue", "yellow", "red"),
             repel = TRUE) +
  labs(title = "Contributo delle variabili (PCA 1 e PCA 2)")
# Visualizza il contributo per PCA 3
fviz_pca_var(pca_result, axes = c(1, 3),
             col.var = "contrib",
             gradient.cols = c("blue", "yellow", "red"),
             repel = TRUE) +
  labs(title = "Contributo delle variabili (PCA 1 e PCA 3)")

# Funzione per creare un grafico dei loadings per una componente specifica
plot_loadings <- function(loadings_sorted, pca_num) {
  loadings_df <- data.frame(Variable = names(loadings_sorted), Loading = loadings_sorted)
  ggplot(loadings_df, aes(x = reorder(Variable, Loading), y = Loading)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    coord_flip() +  # Per ruotare il grafico
    labs(title = paste("Loadings per PCA", pca_num), x = "Variabili", y = "Loading")
}

# Creazione dei grafici per PCA1, PCA2 e PCA3
plot_loadings(loading_pca1, 1)
plot_loadings(loading_pca2, 2)
plot_loadings(loading_pca3, 3)


# Vediamo se c'è una correlazine in base alla posizione territoriale (Nord, Sud , Centro)
# Calcola i centroidi delle regioni
region_means <- pca_data %>%
  group_by(Region) %>%
  summarise(Dim1_mean = mean(Dim.1), Dim2_mean = mean(Dim.2))
# Visualizza i centroidi per verifica
print(region_means)

```


K-Mean Clustering
```{r}

# Selezioniamo le PCA
pca_kmeans <- pca_data %>% select(-Region, -Municipality)

# Verifica numero ottimale di cluster tramite silhouette
fviz_nbclust(pca_kmeans, kmeans, method = "wss")

km.res <- kmeans(pca_kmeans, 2)
sil <- silhouette(km.res$cluster, dist(pca_kmeans))
fviz_silhouette(sil)

km.res <- kmeans(pca_kmeans, 3)
sil <- silhouette(km.res$cluster, dist(pca_kmeans))
fviz_silhouette(sil)

km.res <- kmeans(pca_kmeans, 7)
sil <- silhouette(km.res$cluster, dist(pca_kmeans))
fviz_silhouette(sil)

km.res <- kmeans(pca_kmeans, 8)
sil <- silhouette(km.res$cluster, dist(pca_kmeans))
fviz_silhouette(sil)

km.res.2 <- kmeans(pca_kmeans, 2)

fviz_cluster(km.res.2, data = pca_kmeans)+theme_minimal()

# Troviamo la media di ogni cluster
aggregate(pca_kmeans, by=list(cluster=km.res.2$cluster), mean)

final_data <- cbind(pca_kmeans, Cluster = km.res.2$cluster)

```


Esempi di grafici interpretativi K-Mean Clustering
```{r}

# Prima di tutto, aggiungiamo la colonna dei cluster al dataset per poter fare le visualizzazioni
pca_data$Cluster <- km.res.2$cluster

# 1. Grafico della distribuzione dei cluster nelle prime due componenti principali
ggplot(pca_data, aes(x = Dim.1, y = Dim.2, color = as.factor(Cluster))) +
  geom_point(size = 3) +
  theme_minimal() +
  labs(title = "Distribuzione dei Cluster sulle Prime Due Componenti Principali",
       x = "PCA 1", y = "PCA 2", color = "Cluster")

# 2. Grafico dei cluster suddivisi per Regione
ggplot(pca_data, aes(x = Dim.1, y = Dim.2, color = Region)) +
  geom_point(aes(shape = as.factor(Cluster)), size = 3) +
  theme_minimal() +
  labs(title = "Distribuzione dei Cluster Suddivisi per Regione",
       x = "PCA 1", y = "PCA 2", color = "Regione", shape = "Cluster") +
  scale_color_manual(values = c(
    "red", "blue", "green", "orange", "purple", "brown", "pink", "cyan", "yellow", "black",
    "darkred", "darkblue", "darkgreen", "gold", "violet", "chocolate", "turquoise", "gray", "darkorange", "navy"
  ))

# 3. Grafico dei cluster suddivisi per Anno (assumendo che esista una colonna 'Year')
pca_data$Year <- data$Year
ggplot(pca_data, aes(x = Dim.1, y = Dim.2, color = as.factor(Year))) +
  geom_point(aes(shape = as.factor(Cluster)), size = 3) +
  theme_minimal() +
  labs(title = "Distribuzione dei Cluster Suddivisi per Anno",
       x = "PCA 1", y = "PCA 2", color = "Anno", shape = "Cluster") +
  scale_color_manual(values = c(
    "2019" = "red", "2020" = "blue", "2021" = "green", "2022" = "orange", "2023" = "purple"
  ))

# 4. Boxplot dei cluster per variabili specifiche, suddivisi per Regione
ggplot(final_data, aes(x = as.factor(Cluster), y = Dim.1, fill = as.factor(Cluster))) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Distribuzione per Cluster: Dimensione 1",
       x = "Cluster", y = "Dimensione 1") +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral"))

# 5. Grafico a barre della media di una variabile per ciascun cluster, diviso per Regione
final_data$Region <- data$Region
aggregate_data <- final_data %>%
  group_by(Cluster, Region) %>%
  summarise(Dimensione1 = mean(Dim.1))

ggplot(aggregate_data, aes(x = Region, y = Dimensione1, fill = as.factor(Cluster))) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media di Dimensione 1 per Regione e Cluster",
       x = "Regione", y = "Dim 1") +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral"))

# 6. Confronto tra i cluster per variabili temporali (se la variabile Anno esiste)
final_data$Year <- data$Year
aggregate_year <- final_data %>%
  group_by(Cluster, Year) %>%
  summarise(Dimensione1 = mean(Dim.1))

ggplot(aggregate_year, aes(x = as.factor(Year), y = Dimensione1, fill = as.factor(Cluster))) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_minimal() +
  labs(title = "Media di Dimensione 1 per Anno e Cluster", x = "Anno", y = "Dim 1") +
  scale_fill_manual(values = c("lightblue", "lightgreen", "lightcoral"))

```


Hierarchical Clustering
```{r}

# Selezioniamo le PCA
pca_hierarchical <- pca_data %>% select(-Region, -Municipality)

# Definiamo linkage methods
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

# Function to compute agglomerative coefficient
ac <- function(x) {
  agnes(pca_hierarchical, method = x)$ac
}

# Calcoliamo agglomerative coefficient per ogni clustering linkage method
sapply(m, ac)

# WARD SEEMS THE BEST IN AGGLOMERATIVE COEFFICIENT

# Perform hierarchical clustering using Ward's minimum variance
clust <- agnes(pca_hierarchical, method = "ward")

# Produce dendrogram
pltree(clust, cex = 0.6, hang = -1, main = "Dendrogram")

# NOW WE NEED TO SELECT THE NUMBER OF CLUSTER (SIMILAR TO THE K IN THE K MEANS)
# WE USE THE GAP STATISTICS

# Calculate gap statistic for each number of clusters (up to 5 clusters)
gap_stat <- clusGap(pca_hierarchical, FUN = hcut, nstart = 25, K.max = 5, B = 50)

# Produce plot of clusters vs. gap statistic
fviz_gap_stat(gap_stat)

# THE HIGHEST GAP STASTISTICS IS IN K=3

# Compute distance matrix
d <- dist(pca_hierarchical, method = "euclidean")
final_clust <- hclust(d, method = "ward.D2" )
groups <- cutree(final_clust, k=3)
plot(final_clust)
rect.hclust(final_clust, k = 3, border = "green")

pca_hierarchical$Region <- pca_data$Region
pca_hierarchical$Municipality <- pca_data$Municipality

final_data <- cbind(pca_hierarchical, cluster = groups)
aggregate(final_data, by=list(cluster=final_data$cluster), mean)

ggplot(final_data) +
  aes(x = Dim.1, y = Dim.2, colour = as.factor(cluster)) +
  geom_point(shape = "circle", size = 1.5) +
  theme_minimal()

# Crea il grafico con ggplot2, colorando in base alla regione
ggplot(final_data, aes(x = Dim.1, y = Dim.2, color = Region)) +
  geom_point(shape = "circle", size = 1.5) +
  theme_minimal() +
  labs(title = "Proiezione delle osservazioni colorata per regione",
       x = "PCA 1", y = "PCA 2") +
  scale_color_manual(values = c(
    "red", "blue", "green", "orange", "purple", "brown", "pink", "cyan", "yellow", 
    "black", "darkred", "darkblue", "darkgreen", "gold", "violet", "chocolate", 
    "turquoise", "gray", "darkorange", "navy"
  )) +
  theme(legend.title = element_blank())  # Rimuove il titolo della legenda

# Crea il grafico con faceting per anno
final_data$Year <- data_numeric$Year
ggplot(final_data, aes(x = Dim.1, y = Dim.2, color = Region)) +
  geom_point(shape = "circle", size = 1.5) +
  theme_minimal() +
  labs(title = "Proiezione delle osservazioni colorata per regione e divisa per anno",
       x = "PCA 1", y = "PCA 2") +
  scale_color_manual(values = c(
    "red", "blue", "green", "orange", "purple", "brown", "pink", "cyan", "yellow", 
    "black", "darkred", "darkblue", "darkgreen", "gold", "violet", "chocolate", 
    "turquoise", "gray", "darkorange", "navy"
  )) +
  theme(legend.title = element_blank()) +  # Rimuove il titolo della legenda
  facet_wrap(~ Year, scales = "free")  # Facet per anno

```


DBScan Clustering
```{r}

# Selezioniamo le prime due componenti principali per il clustering (Dim.1 e Dim.2)
# Usa anche altre dimensioni se necessario
pca_data_dbscan <- pca_data %>% select(Dim.1, Dim.2)

# Esegui il clustering DBSCAN
# Parametri eps e minPts devono essere scelti con attenzione (eps è la distanza massima per la vicinanza)
# minPts è il numero minimo di punti per formare un cluster

# Selection of minpts: log(n) ---> log(498) = 6.2
# Selection of EPS using k=datasetdimension + 1

kNNdistplot(pca_data_dbscan, k = 3)
abline(h=.85, col = "red", lty=2)

dbscan_result <- dbscan(pca_data_dbscan, eps = 1, minPts = 6.2)
dbscan_result

hullplot(x = pca_data_dbscan, cl = dbscan_result) # grafico delle aree convesse

final_data=cbind(pca_data_dbscan, Cluster=dbscan_result$cluster)

# Visualizza i cluster
table(dbscan_result$cluster)

# Crea una mappa dei cluster (colorata in base al cluster)
ggplot(pca_data, aes(x = Dim.1, y = Dim.2, color = factor(dbscan_result$cluster))) +
  geom_point() +
  labs(title = "DBSCAN Clustering", color = "Cluster") +
  theme_minimal()

# Se vuoi aggiungere le informazioni sui cluster ai dati originali
pca_data$DBSCAN_Cluster <- dbscan_result$cluster

# Visualizza i primi 6 dati con cluster assegnato
head(pca_data)

```


Esempi di grafici interpretativi su DBScan Clustering
```{r}

# Crea una mappa dei cluster (colorata in base al cluster)
ggplot(pca_data, aes(x = Dim.1, y = Dim.2, color = factor(dbscan_result$cluster))) +
  geom_point() +
  labs(title = "DBSCAN Clustering", color = "Cluster") +
  theme_minimal()

# Se vuoi aggiungere le informazioni sui cluster ai dati originali
pca_data$DBSCAN_Cluster <- dbscan_result$cluster

# Visualizza i primi 6 dati con cluster assegnato
head(pca_data)

# Contare il numero di regioni per cluster
cluster_counts <- pca_data %>%
  group_by(DBSCAN_Cluster, Region) %>%
  summarise(Count = n()) %>%
  filter(DBSCAN_Cluster != 0) # Ignora il cluster di rumore (0)

# Grafico a barre per distribuzione delle regioni nei cluster
ggplot(cluster_counts, aes(x = factor(DBSCAN_Cluster), y = Count, fill = Region)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Distribuzione delle Regioni nei Cluster", x = "Cluster", y = "Numero di Occorrenze") +
  scale_fill_brewer(palette = "Paired") +
  theme_minimal()

# Assumendo di avere una colonna "Year" nei dati
pca_data$Year <- data$Year  # Aggiungi l'anno, se non presente

# Distribuzione per cluster e anno
cluster_year <- pca_data %>%
  group_by(DBSCAN_Cluster, Year) %>%
  summarise(Count = n()) %>%
  filter(DBSCAN_Cluster != 0)

# Grafico a linee per mostrare l'evoluzione temporale dei cluster
ggplot(cluster_year, aes(x = Year, y = Count, color = factor(DBSCAN_Cluster), group = DBSCAN_Cluster)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  labs(title = "Evoluzione Temporale dei Cluster", x = "Anno", y = "Numero di Occorrenze", color = "Cluster") +
  theme_minimal()

# Calcolo delle medie delle variabili numeriche per cluster e regione
cluster_summary <- pca_data %>%
  group_by(DBSCAN_Cluster, Region) %>%
  summarise(across(starts_with("Dim"), mean, na.rm = TRUE)) %>%
  filter(DBSCAN_Cluster != 0)

# Converti in formato lungo per creare una heatmap
heatmap_data <- cluster_summary %>%
  pivot_longer(cols = starts_with("Dim"), names_to = "Dimension", values_to = "MeanValue")

# Heatmap
ggplot(heatmap_data, aes(x = Region, y = Dimension, fill = MeanValue)) +
  geom_tile(color = "white") +
  facet_wrap(~ DBSCAN_Cluster, ncol = 1) +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "Heatmap dei Cluster per Regione e Variabili", x = "Regione", y = "Dimensione", fill = "Valore Medio") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

